<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>A tale of two lengths</title>
        
        <meta name="description" content="Adventures in memory profiling a rust-based cache" />
        
        <link rel="alternate" type="application/rss+xml" href="/rss.xml" />
        <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
        <script
            defer
            data-domain="cetra3.github.io"
            src="https://track.divedb.net/js/plausible.js"
        ></script>
        <style>
            html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;}body{margin:0}article,aside,footer,header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figcaption,figure,main{display:block}hr{box-sizing:content-box;height:0;overflow:visible;}a{background-color:rgba(0,0,0,0);-webkit-text-decoration-skip:objects;}a:active,a:hover{outline-width:0}address{font-style:normal}b,strong{font-weight:inherit}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:"SF Mono","Segoe UI Mono","Roboto Mono",Menlo,Courier,monospace;font-size:1em;}dfn{font-style:italic}small{font-size:80%;font-weight:400;}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}audio,video{display:inline-block}audio:not([controls]){display:none;height:0}img{border-style:none}svg:not(:root){overflow:hidden}button,input,optgroup,select,textarea{font-family:inherit;font-size:inherit;line-height:inherit;margin:0;}button,input{overflow:visible}button,select{text-transform:none}button,html [type=button],[type=reset],[type=submit]{-webkit-appearance:button;}button::-moz-focus-inner,[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner{border-style:none;padding:0}fieldset{border:0;margin:0;padding:0}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal;}progress{display:inline-block;vertical-align:baseline;}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0;}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px;}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit;}details,menu{display:block}summary{display:list-item;outline:none}canvas{display:inline-block}template{display:none}[hidden]{display:none}*,*::before,*::after{box-sizing:inherit}html{box-sizing:border-box;font-size:20px;line-height:1.5;-webkit-tap-highlight-color:rgba(0,0,0,0)}body{background:#303742;color:#fff;font-family:-apple-system,system-ui,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",sans-serif;font-size:.8rem;overflow-x:hidden;text-rendering:optimizeLegibility}a{color:#73c6ec;outline:none;text-decoration:none}a:focus{box-shadow:0 0 0 .1rem rgba(115,198,236,.2)}a:focus,a:hover,a:active,a.active{color:#46b4e6;text-decoration:underline}a:visited{color:#a0d8f2}h1,h2,h3,h4,h5,h6{color:inherit;font-weight:700;line-height:1.2;margin-bottom:.5rem;margin-top:0}.h1,.h2,.h3,.h4,.h5,.h6{font-weight:700}h1,.h1{font-size:2rem}h2,.h2{font-size:1.6rem}h3,.h3{font-size:1.4rem}h4,.h4{font-size:1.2rem}h5,.h5{font-size:1rem}h6,.h6{font-size:.8rem}p{margin:0 0 1.2rem}a,ins,u{text-decoration-skip:ink edges}abbr[title]{border-bottom:.05rem dotted;cursor:help;text-decoration:none}kbd{border-radius:.1rem;line-height:1.2;padding:.1rem .2rem;background:#303742;color:#fff;font-size:.7rem}mark{background:#ffe9b3;color:#fff;border-bottom:.05rem solid #ffd367;border-radius:.1rem;padding:.05rem .1rem 0}blockquote{border-left:.1rem solid #dadee4;margin-left:0;padding:.4rem .8rem}blockquote p:last-child{margin-bottom:0}ul,ol{margin:.8rem 0 .8rem .8rem;padding:0}ul ul,ul ol,ol ul,ol ol{margin:.8rem 0 .8rem .8rem}ul li,ol li{margin-top:.4rem}ul{list-style:disc inside}ul ul{list-style-type:circle}ol{list-style:decimal inside}ol ol{list-style-type:lower-alpha}dl dt{font-weight:bold}dl dd{margin:.4rem 0 .8rem 0}.btn{appearance:none;background:#fff;border:.05rem solid #73c6ec;border-radius:.1rem;color:#73c6ec;cursor:pointer;display:inline-block;font-size:.8rem;height:2.5rem;line-height:1.2rem;outline:none;padding:.6rem .4rem;text-align:center;text-decoration:none;transition:background .2s,border .2s,box-shadow .2s,color .2s;user-select:none;vertical-align:middle;white-space:nowrap}.btn:focus{box-shadow:0 0 0 .1rem rgba(115,198,236,.2)}.btn:focus,.btn:hover{background:#fff;border-color:#66c1ea;text-decoration:none}.btn:active,.btn.active{background:#66c1ea;border-color:#4fb7e7;color:#fff;text-decoration:none}.btn:active.loading::after,.btn.active.loading::after{border-bottom-color:#fff;border-left-color:#fff}.btn[disabled],.btn:disabled,.btn.disabled{cursor:default;opacity:.5;pointer-events:none}.btn.btn-primary{background:#73c6ec;border-color:#66c1ea;color:#fff}.btn.btn-primary:focus,.btn.btn-primary:hover{background:#5dbde9;border-color:#4fb7e7;color:#fff}.btn.btn-primary:active,.btn.btn-primary.active{background:#54b9e8;border-color:#46b4e6;color:#fff}.btn.btn-primary.loading::after{border-bottom-color:#fff;border-left-color:#fff}.btn.btn-success{background:#32b643;border-color:#2faa3f;color:#fff}.btn.btn-success:focus{box-shadow:0 0 0 .1rem rgba(50,182,67,.2)}.btn.btn-success:focus,.btn.btn-success:hover{background:#30ae40;border-color:#2da23c;color:#fff}.btn.btn-success:active,.btn.btn-success.active{background:#2a9a39;border-color:#278e34;color:#fff}.btn.btn-success.loading::after{border-bottom-color:#fff;border-left-color:#fff}.btn.btn-error{background:#e85600;border-color:#d95000;color:#fff}.btn.btn-error:focus{box-shadow:0 0 0 .1rem rgba(232,86,0,.2)}.btn.btn-error:focus,.btn.btn-error:hover{background:#de5200;border-color:#cf4d00;color:#fff}.btn.btn-error:active,.btn.btn-error.active{background:#c44900;border-color:#b54300;color:#fff}.btn.btn-error.loading::after{border-bottom-color:#fff;border-left-color:#fff}.btn.btn-link{background:rgba(0,0,0,0);border-color:rgba(0,0,0,0);color:#73c6ec}.btn.btn-link:focus,.btn.btn-link:hover,.btn.btn-link:active,.btn.btn-link.active{color:#46b4e6}.btn.btn-sm{font-size:.7rem;height:1.4rem;padding:.05rem .3rem}.btn.btn-lg{font-size:.9rem;height:2rem;padding:.35rem .6rem}.btn.btn-block{display:block;width:100%}.btn.btn-action{width:2.5rem;padding-left:0;padding-right:0}.btn.btn-action.btn-sm{width:1.4rem}.btn.btn-action.btn-lg{width:2rem}.btn.btn-clear{background:rgba(0,0,0,0);border:0;color:currentColor;height:1rem;line-height:.8rem;margin-left:.2rem;margin-right:-2px;opacity:1;padding:.1rem;text-decoration:none;width:1rem}.btn.btn-clear:focus,.btn.btn-clear:hover{background:rgba(48,55,66,.5);opacity:.95}.btn.btn-clear::before{content:"âœ•"}.btn-group{display:inline-flex;flex-wrap:wrap}.btn-group .btn{flex:1 0 auto}.btn-group .btn:first-child:not(:last-child){border-bottom-right-radius:0;border-top-right-radius:0}.btn-group .btn:not(:first-child):not(:last-child){border-radius:0;margin-left:-.05rem}.btn-group .btn:last-child:not(:first-child){border-bottom-left-radius:0;border-top-left-radius:0;margin-left:-.05rem}.btn-group .btn:focus,.btn-group .btn:hover,.btn-group .btn:active,.btn-group .btn.active{z-index:1}.btn-group.btn-group-block{display:flex}.btn-group.btn-group-block .btn{flex:1 0 0}.label{border-radius:.1rem;line-height:1.2;padding:.1rem .2rem;background:#39414e;color:#e6e6e6;display:inline-block}.label.label-rounded{border-radius:5rem;padding-left:.4rem;padding-right:.4rem}.label.label-primary{background:#0b3e55;color:#fff}.label.label-secondary{background:#fff;color:#73c6ec}.label.label-success{background:#32b643;color:#fff}.label.label-warning{background:#ffb700;color:#fff}.label.label-error{background:#e85600;color:#fff}p code{border-radius:.1rem;line-height:1.2;padding:.1rem .2rem;background:#0f4e6b;color:#fff;font-size:85%}.code{border-radius:.1rem;color:#fff;position:relative}.code::before{color:#bcc3ce;content:attr(data-lang);font-size:.7rem;position:absolute;right:.4rem;top:.1rem}.code code{background:#303742;color:inherit;display:block;line-height:1.5;overflow-x:auto;padding:1rem;width:100%}.container{margin-left:auto;margin-right:auto;padding-left:.4rem;padding-right:.4rem;width:100%}.container.grid-xl{max-width:1296px}.container.grid-lg{max-width:976px}.container.grid-md{max-width:856px}.container.grid-sm{max-width:616px}.container.grid-xs{max-width:496px}.show-xs,.show-sm,.show-md,.show-lg,.show-xl{display:none !important}.columns{display:flex;flex-wrap:wrap;margin-left:-.4rem;margin-right:-.4rem}.columns.col-gapless{margin-left:0;margin-right:0}.columns.col-gapless>.column{padding-left:0;padding-right:0}.columns.col-oneline{flex-wrap:nowrap;overflow-x:auto}.column{flex:1;max-width:100%;padding-left:.4rem;padding-right:.4rem}.column.col-12,.column.col-11,.column.col-10,.column.col-9,.column.col-8,.column.col-7,.column.col-6,.column.col-5,.column.col-4,.column.col-3,.column.col-2,.column.col-1{flex:none}.col-12{width:100%}.col-11{width:91.66666667%}.col-10{width:83.33333333%}.col-9{width:75%}.col-8{width:66.66666667%}.col-7{width:58.33333333%}.col-6{width:50%}.col-5{width:41.66666667%}.col-4{width:33.33333333%}.col-3{width:25%}.col-2{width:16.66666667%}.col-1{width:8.33333333%}.col-auto{flex:0 0 auto;max-width:none;width:auto}.col-mx-auto{margin-left:auto;margin-right:auto}.col-ml-auto{margin-left:auto}.col-mr-auto{margin-right:auto}@media (max-width: 1280px){.col-xl-12,.col-xl-11,.col-xl-10,.col-xl-9,.col-xl-8,.col-xl-7,.col-xl-6,.col-xl-5,.col-xl-4,.col-xl-3,.col-xl-2,.col-xl-1{flex:none}.col-xl-12{width:100%}.col-xl-11{width:91.66666667%}.col-xl-10{width:83.33333333%}.col-xl-9{width:75%}.col-xl-8{width:66.66666667%}.col-xl-7{width:58.33333333%}.col-xl-6{width:50%}.col-xl-5{width:41.66666667%}.col-xl-4{width:33.33333333%}.col-xl-3{width:25%}.col-xl-2{width:16.66666667%}.col-xl-1{width:8.33333333%}.hide-xl{display:none !important}.show-xl{display:block !important}}@media (max-width: 960px){.col-lg-12,.col-lg-11,.col-lg-10,.col-lg-9,.col-lg-8,.col-lg-7,.col-lg-6,.col-lg-5,.col-lg-4,.col-lg-3,.col-lg-2,.col-lg-1{flex:none}.col-lg-12{width:100%}.col-lg-11{width:91.66666667%}.col-lg-10{width:83.33333333%}.col-lg-9{width:75%}.col-lg-8{width:66.66666667%}.col-lg-7{width:58.33333333%}.col-lg-6{width:50%}.col-lg-5{width:41.66666667%}.col-lg-4{width:33.33333333%}.col-lg-3{width:25%}.col-lg-2{width:16.66666667%}.col-lg-1{width:8.33333333%}.hide-lg{display:none !important}.show-lg{display:block !important}}@media (max-width: 840px){.col-md-12,.col-md-11,.col-md-10,.col-md-9,.col-md-8,.col-md-7,.col-md-6,.col-md-5,.col-md-4,.col-md-3,.col-md-2,.col-md-1{flex:none}.col-md-12{width:100%}.col-md-11{width:91.66666667%}.col-md-10{width:83.33333333%}.col-md-9{width:75%}.col-md-8{width:66.66666667%}.col-md-7{width:58.33333333%}.col-md-6{width:50%}.col-md-5{width:41.66666667%}.col-md-4{width:33.33333333%}.col-md-3{width:25%}.col-md-2{width:16.66666667%}.col-md-1{width:8.33333333%}.hide-md{display:none !important}.show-md{display:block !important}}@media (max-width: 600px){.col-sm-12,.col-sm-11,.col-sm-10,.col-sm-9,.col-sm-8,.col-sm-7,.col-sm-6,.col-sm-5,.col-sm-4,.col-sm-3,.col-sm-2,.col-sm-1{flex:none}.col-sm-12{width:100%}.col-sm-11{width:91.66666667%}.col-sm-10{width:83.33333333%}.col-sm-9{width:75%}.col-sm-8{width:66.66666667%}.col-sm-7{width:58.33333333%}.col-sm-6{width:50%}.col-sm-5{width:41.66666667%}.col-sm-4{width:33.33333333%}.col-sm-3{width:25%}.col-sm-2{width:16.66666667%}.col-sm-1{width:8.33333333%}.hide-sm{display:none !important}.show-sm{display:block !important}}@media (max-width: 480px){.col-xs-12,.col-xs-11,.col-xs-10,.col-xs-9,.col-xs-8,.col-xs-7,.col-xs-6,.col-xs-5,.col-xs-4,.col-xs-3,.col-xs-2,.col-xs-1{flex:none}.col-xs-12{width:100%}.col-xs-11{width:91.66666667%}.col-xs-10{width:83.33333333%}.col-xs-9{width:75%}.col-xs-8{width:66.66666667%}.col-xs-7{width:58.33333333%}.col-xs-6{width:50%}.col-xs-5{width:41.66666667%}.col-xs-4{width:33.33333333%}.col-xs-3{width:25%}.col-xs-2{width:16.66666667%}.col-xs-1{width:8.33333333%}.hide-xs{display:none !important}.show-xs{display:block !important}}.navbar{align-items:stretch;display:flex;flex-wrap:wrap;justify-content:space-between;margin-left:auto;margin-right:auto;max-width:960px}.navbar .navbar-section{align-items:center;display:flex;flex:1 0 0}.navbar .navbar-section:not(:first-child):last-child{justify-content:flex-end}.navbar .navbar-center{align-items:center;display:flex;flex:0 0 auto}.navbar .navbar-brand{font-size:.9rem;text-decoration:none}pre{padding:.5rem .5rem;border-radius:.3rem;overflow-y:auto}.giallo-l{display:inline-block;min-height:1lh;width:100%}.giallo-ln{display:inline-block;user-select:none;margin-right:.4em;padding:.4em;min-width:3ch;text-align:right;opacity:.8}.post header{border-radius:.3rem;padding:.5rem;margin-bottom:.5rem}.post header h1{margin-bottom:0}.post section{padding:.5rem;background-color:#2a3039;border-radius:.3rem}.post img{display:block;margin:0 auto;max-width:100%}.post .utterances{max-width:none !important}.card{margin-bottom:.5rem}.main-header{margin-bottom:.5rem;background-color:#272d36;box-shadow:0 20rem 20rem 20rem rgba(115,198,236,.2)}.card{background:#2a3039;border-radius:.3rem;display:flex;flex-direction:column}.card .card-header,.card .card-body,.card .card-footer{padding:.8rem;padding-bottom:0}.card .card-header:last-child,.card .card-body:last-child,.card .card-footer:last-child{padding-bottom:.8rem}.card .card-body{flex:1 1 auto}.card .card-image{padding-top:.8rem}.card .card-image:first-child{padding-top:0}.card .card-image:first-child img{border-top-left-radius:.1rem;border-top-right-radius:.1rem}.card .card-image:last-child img{border-bottom-left-radius:.1rem;border-bottom-right-radius:.1rem}
        </style>
    </head>

    <body>
        <header class="main-header">
            <div class="navbar">
                <section class="navbar-section">
                    <img src="/favicon.svg" width="30" height="30" />
                    <a href="/" class="btn btn-link">Home</a>
                    <a href="/blog/" class="btn btn-link">Blogs</a>
                    <a href="/rss.xml" class="btn btn-link">RSS</a>
                </section>
                <section class="navbar-center"></section>
                <section class="navbar-section">
                    <a href="https://github.com/cetra3/" class="btn btn-link"
                        >GitHub</a
                    >
                    <a
                        href="https://mastodon.social/@cetra3"
                        class="btn btn-link"
                        >Mastodon</a
                    >
                </section>
            </div>
        </header>
        <div class="container grid-lg">
            
<article class="post">
  <header>
  <h1>A tale of two lengths </h1>
  <em>Adventures in memory profiling a rust-based cache</em>
  <br />
  
  <small class="label label-primary">rust</small> <small class="label">2025-05-11</small>
  
  </header>
  <section>
    <p>They say there are 2 hard problems in computer science, and I've hit all 3 of them....  This is a blog post about a memory problem we were hitting in production with a service written in rust, and the tools used to resolve it.</p>
<h2 id="the-problem">The Problem</h2>
<p>Object Storage, whether S3 or something else, does not have the best performance for latency in comparison to local disk.  There can be a lot of overhead to retrieving files.  Alongside this, repetitive calls to the same files means that you will have multiple requests to the same data.  One solution is to have a local cache of files sitting close to wherever you are using them.  That way, for regularly requested files, you can reduce latency and decrease the amount of requests to the backing object store.</p>
<p>For a possible solution, we recently moved to using <a rel="external" href="https://foyer.rs/"><code>foyer</code></a>, touted as a <em>hybrid cache</em>, as it provides not only a memory cache, but can be used with local disk storage as well. For really hot files, they would be served in memory.  For colder files, they could be read from a local ephemeral ssd, so still providing some speedup even if evicted from memory.  This looked like a great fit for our use case.</p>
<p>Things looked like they were going OK, until the cache had been running for a day or so. We noticed that the memory limits we were setting were not honoured, and we were seeing pod restarts with the reason set to <a rel="external" href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/#exceed-a-container-s-memory-limit"><code>OOMKilled</code></a>. Something about how we configured the cache was not right.</p>
<h3 id="cache-layout">Cache Layout</h3>
<p>In our setup, we don't want to actually cache entire files, just the ranges of bytes that have been requested.  Our request pattern means there is never any overlap between ranges, and the exact same ranges are going to be requested repeatedly.</p>
<p>So our Cache Key essentially looks like:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">struct</span><span style="color: #73D0FF;"> CacheKey</span><span> {</span></span>
<span class="giallo-l"><span>    path</span><span style="color: #F29E74;">:</span><span style="color: #73D0FF;"> String</span><span>,</span></span>
<span class="giallo-l"><span>    start</span><span style="color: #F29E74;">:</span><span style="color: #73D0FF;"> usize</span><span>,</span></span>
<span class="giallo-l"><span>    end</span><span style="color: #F29E74;">:</span><span style="color: #73D0FF;"> usize</span><span>,</span></span>
<span class="giallo-l"><span>}</span></span></code></pre>
<p>And our Cache Value is standard <a rel="external" href="https://docs.rs/bytes/latest/bytes/struct.Bytes.html"><code>Bytes</code></a>, giving us a cache that looks a bit like this:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">struct</span><span style="color: #73D0FF;"> ByteCacheAppState</span><span> {</span></span>
<span class="giallo-l"><span>    write_cache</span><span style="color: #F29E74;">:</span><span style="color: #73D0FF;"> HybridCache</span><span>&lt;</span><span style="color: #73D0FF;">CacheKey</span><span>,</span><span style="color: #73D0FF;"> Bytes</span><span>&gt;,</span></span>
<span class="giallo-l"><span>}</span></span></code></pre>
<p>Of course with a cache we can't have <em>unbounded</em> memory usage.  So we configure a weighter that uses the length of bytes in memory (plus a <code>memory_size</code> method for the key to account for the path string + two usizes, even if it's insignificant: we want to be as accurate as possible!):</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #F29E74;">...</span></span>
<span class="giallo-l"><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">with_weighter</span><span>(</span><span style="color: #F29E74;">|</span><span>key, value</span><span style="color: #F29E74;">|</span><span> key</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">memory_size</span><span>()</span><span style="color: #F29E74;"> +</span><span> value</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">len</span><span>())</span></span>
<span class="giallo-l"><span style="color: #F29E74;">...</span></span></code></pre>
<p>The <code>Bytes</code> struct is a bit of a special struct that is used in a lot of crates.  It's essentially an <code>Arc&lt;[u8]&gt;</code> but has some magic to deal with other backing implementations.  It's cheaply cloneable: the underlying memory isn't cloned, just a reference count is updated.  You can also take a subslice into it as well, so that you can have a view into a portion of the backing bytes, without reallocating.</p>
<h3 id="byte-request">Byte Request</h3>
<p>When we get a request for a range of bytes, we want to either return that ranges bytes if it's in the cache (either memory or disk), or read from object storage, storing that in the cache, and returning the bytes.</p>
<p>With <code>foyer</code> you can use the <a rel="external" href="https://docs.rs/foyer/latest/foyer/struct.HybridCache.html#method.fetch"><code>fetch</code></a> method to do just that:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let</span><span> cache_entry</span><span style="color: #F29E74;"> =</span><span> write_cache</span></span>
<span class="giallo-l"><span style="color: #F29E74;">    .</span><span style="color: #FFCD66;">fetch</span><span>(cache_key,</span><span style="color: #F29E74;"> ||</span><span style="color: #FFA659;"> async move</span><span> {</span></span>
<span class="giallo-l"><span style="color: #FFA659;">        let mut</span><span> req</span><span style="color: #F29E74;"> =</span><span style="color: #FFCD66;"> read_from_store</span><span>(</span><span style="color: #F29E74;">&amp;</span><span>path, range,</span><span style="color: #F29E74;"> &amp;</span><span>store)</span><span style="color: #F29E74;">.</span><span style="color: #FFA659;">await</span><span style="color: #F29E74;">?</span><span>;</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFA659;">        let mut</span><span> buffer</span><span style="color: #F29E74;"> =</span><span style="color: #73D0FF;"> BytesMut</span><span style="color: #F29E74;">::</span><span style="color: #FFCD66;">with_capacity</span><span>(byte_len);</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFA659;">        while let</span><span style="color: #73D0FF;"> Some</span><span>(bytes)</span><span style="color: #F29E74;"> =</span><span> req</span><span style="color: #F29E74;">.</span><span>stream</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">try_next</span><span>()</span><span style="color: #F29E74;">.</span><span style="color: #FFA659;">await</span><span style="color: #F29E74;">?</span><span> {</span></span>
<span class="giallo-l"><span>            buffer</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">extend_from_slice</span><span>(</span><span style="color: #F29E74;">&amp;</span><span>bytes);</span></span>
<span class="giallo-l"><span>        }</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #73D0FF;">        Ok</span><span>(bytes</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">freeze</span><span>())</span></span>
<span class="giallo-l"><span>    })</span></span>
<span class="giallo-l"><span style="color: #F29E74;">    .</span><span style="color: #FFA659;">await</span><span style="color: #F29E74;">?</span><span>;</span></span></code></pre>
<p>And so our cache is pretty simple.  We keep around slices of files that have been requested on the predicted chance that they will be requested again.</p>
<h2 id="troubleshooting">Troubleshooting</h2>
<p>Since we were running into memory limit situations, we started troubleshooting what could possibly be wrong.</p>
<p>The first thing that we tried, was to reduce the limits that we gave to the cache to be much less than the memory limits of the pod, to see if it would plateau albeit at a higher limit.  This <em>seemed</em> to have worked but was still a bit variable in our memory usage.  And we still didn't know where the extra memory usage was coming from.  We really needed to see what was going on with the heap.</p>
<p>One of the <em>advantages</em> of garbage collected languages is that you can really easily introspect the heap. For rust this was traditionally a bit harder. However, there are now some awesome tools we can use to investigate memory allocations.  One we ended up using to troubleshoot was the <a rel="external" href="https://github.com/polarsignals/rust-jemalloc-pprof"><code>jemalloc_pprof</code></a> crate.</p>
<h3 id="profiling-with-jemalloc-pprof">Profiling with <code>jemalloc_pprof</code></h3>
<p>One way to profile memory usage is to have jemalloc as the global allocator, set some settings to turn on profiling, and then use <code>jemalloc_pprof</code> to dump out the heap profile.</p>
<p>The cache is a simple <a rel="external" href="https://github.com/tokio-rs/axum"><code>axum</code></a> webserver, so we ended up creating a request endpoint we could use to read the allocation profile when the cache was warmed up.</p>
<p>Here's how you can add this to your own project, if you wanted to follow along:</p>
<p>Firstly, add <code>tikv-jemallocator</code> and the <code>jemalloc_pprof</code> crate to <code>Cargo.toml</code> with a couple of enabled features:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="toml"><span class="giallo-l"><span>tikv-jemallocator</span><span style="color: #CCCAC2B3;"> =</span><span> { version</span><span style="color: #CCCAC2B3;"> =</span><span style="color: #D5FF80;"> &quot;0.6.0&quot;</span><span style="color: #CCCAC2B3;">,</span><span> features</span><span style="color: #CCCAC2B3;"> =</span><span> [</span><span style="color: #D5FF80;">&quot;profiling&quot;</span><span style="color: #CCCAC2B3;">,</span><span style="color: #D5FF80;"> &quot;unprefixed_malloc_on_supported_platforms&quot;</span><span>] }</span></span>
<span class="giallo-l"><span>jemalloc_pprof</span><span style="color: #CCCAC2B3;"> =</span><span> {version</span><span style="color: #CCCAC2B3;"> =</span><span style="color: #D5FF80;"> &quot;0.7.0&quot;</span><span style="color: #CCCAC2B3;">,</span><span> features</span><span style="color: #CCCAC2B3;"> =</span><span> [</span><span style="color: #D5FF80;">&quot;symbolize&quot;</span><span>]}</span></span></code></pre>
<p>Secondly, enable this as the global allocator in <code>main.rs</code>, with some exported settings (see the <a rel="external" href="https://github.com/polarsignals/rust-jemalloc-pprof"><code>jemalloc_pprof</code> readme</a> for an explanation):</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span>#[global_allocator]</span></span>
<span class="giallo-l"><span style="color: #FFA659;">static</span><span style="color: #95E6CB;"> GLOBAL</span><span style="color: #F29E74;">:</span><span style="color: #73D0FF;"> tikv_jemallocator</span><span style="color: #F29E74;">::</span><span style="color: #73D0FF;">Jemalloc</span><span style="color: #F29E74;"> =</span><span style="color: #73D0FF;"> tikv_jemallocator</span><span style="color: #F29E74;">::</span><span style="color: #73D0FF;">Jemalloc</span><span>;</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span>#[allow(non_upper_case_globals)]</span></span>
<span class="giallo-l"><span>#[export_name </span><span style="color: #F29E74;">=</span><span style="color: #D5FF80;"> &quot;malloc_conf&quot;</span><span>]</span></span>
<span class="giallo-l"><span style="color: #FFA659;">pub static</span><span> malloc_conf</span><span style="color: #F29E74;">: &amp;</span><span>[</span><span style="color: #73D0FF;">u8</span><span>]</span><span style="color: #F29E74;"> =</span><span style="color: #D5FF80;"> b&quot;prof:true,prof_active:true,lg_prof_sample:19</span><span style="color: #95E6CB;">\0</span><span style="color: #D5FF80;">&quot;</span><span>;</span></span></code></pre>
<p>Thirdly, make a simple axum request handler to return the heap:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">async fn</span><span style="color: #FFCD66;"> get_heap</span><span>()</span><span style="color: #F29E74;"> -&gt;</span><span style="color: #73D0FF;"> Result</span><span>&lt;</span><span style="color: #73D0FF;">Response</span><span>&lt;</span><span style="color: #73D0FF;">Body</span><span>&gt;,</span><span style="color: #73D0FF;"> Error</span><span>&gt; {</span></span>
<span class="giallo-l"><span style="color: #FFA659;">    let mut</span><span> prof_ctl</span><span style="color: #F29E74;"> =</span><span style="color: #73D0FF;"> jemalloc_pprof</span><span style="color: #F29E74;">::</span><span style="color: #95E6CB;">PROF_CTL</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">as_ref</span><span>()</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">unwrap</span><span>()</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">lock</span><span>()</span><span style="color: #F29E74;">.</span><span style="color: #FFA659;">await</span><span>;</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFA659;">    let</span><span> pprof</span><span style="color: #F29E74;"> =</span><span> prof_ctl</span></span>
<span class="giallo-l"><span style="color: #F29E74;">        .</span><span style="color: #FFCD66;">dump_pprof</span><span>()</span><span style="color: #F29E74;">?</span><span>;</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #73D0FF;">    Ok</span><span>(</span><span style="color: #73D0FF;">Response</span><span style="color: #F29E74;">::</span><span style="color: #FFCD66;">builder</span><span>()</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">status</span><span>(</span><span style="color: #DFBFFF;">200</span><span>)</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">body</span><span>(pprof</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">into</span><span>())</span><span style="color: #F29E74;">?</span><span>)</span></span>
<span class="giallo-l"><span>}</span></span></code></pre>
<p>Lastly, <strong>Run the program</strong> and get some allocations happening.</p>
<h3 id="getting-results">Getting Results</h3>
<p>You can use curl to save the heap locally:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="shellscript"><span class="giallo-l"><span style="color: #73D0FF;">curl</span><span style="color: #D5FF80;"> http://127.0.0.1:8000/path_to_get_heap</span><span style="color: #F29E74;"> &gt;</span><span style="color: #D5FF80;"> heap.pprof</span></span></code></pre>
<p>Then you can use <a rel="external" href="https://github.com/google/pprof"><code>pprof</code></a> to serve the results as a webpage:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="shellscript"><span class="giallo-l"><span style="color: #73D0FF;">pprof</span><span style="color: #95E6CB;"> -http=:8080</span><span style="color: #D5FF80;"> heap.pprof</span></span></code></pre><h2 id="heap-results">Heap Results</h2>
<p>With the cache service instrumented, we ran up an instance with a limit of <code>10GB</code> RAM for the cache.  We then warmed the cache up to the point we were seeing it go above that limit. Then we downloaded the heap, and investigated it.</p>
<p>Tell me if you can spot the issue in the flame graph:</p>
<p><a href="/photos/heap_profile.png"><img src="/photos/heap_profile.png" alt="" /></a></p>
<p>What this profile is showing us is a couple of things: about 2/3 come from our cache <code>fetch</code> implementation using <code>BytesMut</code>, and the other comes from re-hydrated values from the foyer disk cache.</p>
<p>No memory leaks it seems.  However: the amount of bytes that our heap has in total is <code>17GB</code> which is almost <em>twice</em> the amount of memory we have configured in the cache.</p>
<h3 id="bytesmut-and-vec"><code>BytesMut</code> and <code>Vec</code></h3>
<p>When you use <code>BytesMut::with_capacity</code>, this uses <a rel="external" href="https://docs.rs/bytes/latest/src/bytes/bytes_mut.rs.html#148-150"><code>Vec</code> as a backing store</a>:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">pub fn</span><span style="color: #FFCD66;"> with_capacity</span><span>(capacity</span><span style="color: #F29E74;">:</span><span style="color: #73D0FF;"> usize</span><span>)</span><span style="color: #F29E74;"> -&gt;</span><span style="color: #73D0FF;"> BytesMut</span><span> {</span></span>
<span class="giallo-l"><span style="color: #73D0FF;">    BytesMut</span><span style="color: #F29E74;">::</span><span style="color: #FFCD66;">from_vec</span><span>(</span><span style="color: #73D0FF;">Vec</span><span style="color: #F29E74;">::</span><span style="color: #FFCD66;">with_capacity</span><span>(capacity))</span></span>
<span class="giallo-l"><span>}</span></span></code></pre>
<p>Within <code>Vec</code>, there are two lengths.  There is the <code>len()</code> which is how many initialised values it has.  Then there is <code>capacity()</code>, which is how much it's asked the allocator for.  Normally this <code>capacity()</code> is expanded as a power of two when adding values and is always greater than or equal to the length of entries. This can mean the in-memory size is not always what you'd expect.</p>
<p>So we have <em>two</em> lengths to consider: <code>len()</code> and <code>capacity()</code>, but only <code>capacity()</code> gives a more accurate account of memory usage.</p>
<h3 id="bytes-and-capacity"><code>Bytes</code> and <code>capacity()</code></h3>
<p>There is no <code>capacity()</code> method on <code>Bytes</code>, given that its backing could be a number of different implementations.  This isn't <em>great</em> for our use case here, where we want to account for the memory usage more accurately.</p>
<h2 id="changing-to-vec-u8">Changing To <code>Vec&lt;u8&gt;</code></h2>
<p>Since we can't use <code>capacity()</code> on <code>Bytes</code>, one troubleshooting step was that we tried using <code>Vec</code> directly.  This won't give us cheaply cloneable bytes, but it will at least allow us to verify that this is where the extra memory usage comes from.</p>
<p>So we have a cache implementation like:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">struct</span><span style="color: #73D0FF;"> ByteCacheAppState</span><span> {</span></span>
<span class="giallo-l"><span>    write_cache</span><span style="color: #F29E74;">:</span><span style="color: #73D0FF;"> HybridCache</span><span>&lt;</span><span style="color: #73D0FF;">CacheKey</span><span>,</span><span style="color: #73D0FF;"> Vec</span><span>&lt;</span><span style="color: #73D0FF;">u8</span><span>&gt;&gt;,</span></span>
<span class="giallo-l"><span>}</span></span></code></pre>
<p>With a weighter like:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #F29E74;">...</span></span>
<span class="giallo-l"><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">with_weighter</span><span>(</span><span style="color: #F29E74;">|</span><span>key, value</span><span style="color: #F29E74;">|</span><span> key</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">memory_size</span><span>()</span><span style="color: #F29E74;"> +</span><span> value</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">capacity</span><span>())</span></span>
<span class="giallo-l"><span style="color: #F29E74;">...</span></span></code></pre><h3 id="the-new-profile">The New Profile</h3>
<p>OK, running again with a <code>10GB</code> limit, let's have a look at the new flame graph profile:</p>
<p><a href="/photos/heap_profile_vec.png"><img src="/photos/heap_profile_vec.png" alt="" /></a></p>
<p>OK, that looks <em>a lot</em> better!</p>
<h2 id="the-actual-bug">The Actual Bug</h2>
<p>So it looks like the difference between <code>len()</code> and <code>capacity()</code> is our culprit.  We can use this implementation, or use another struct that allows us to read actual capacity.</p>
<p>Problem solved right? However, this <em>is</em> a tale of two lengths!</p>
<h3 id="vec-with-capacity"><code>Vec::with_capacity</code></h3>
<p>After a bit of digging into the way allocating works on a <code>Vec</code>, if you create a <code>Vec</code> with a given capacity, it <em>shouldn't</em> reallocate until the length is greater than the initial capacity, even if it's not a power of two.  Within our <code>fetch()</code> method we are setting the capacity explicitly, so we should only allocate once per cache entry, and not reallocate.</p>
<p><a rel="external" href="https://doc.rust-lang.org/std/vec/struct.Vec.html#method.with_capacity">In the documentation</a> it's implicitly stated that <code>with_capacity</code> does not guarantee that <code>capacity()</code> and <code>len()</code> will be equal, i.e, even in the given the example it's written so:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let mut</span><span> vec</span><span style="color: #F29E74;"> =</span><span style="color: #73D0FF;"> Vec</span><span style="color: #F29E74;">::</span><span style="color: #FFCD66;">with_capacity</span><span>(</span><span style="color: #DFBFFF;">10</span><span>);</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFCD66;">assert_eq!</span><span>(vec</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">len</span><span>(),</span><span style="color: #DFBFFF;"> 0</span><span>);</span></span>
<span class="giallo-l"><span style="color: #FFCD66;">assert!</span><span>(vec</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">capacity</span><span>()</span><span style="color: #F29E74;"> &gt;=</span><span style="color: #DFBFFF;"> 10</span><span>);</span></span></code></pre>
<p>Here that sneaky little <code>&gt;=</code> sign indicates that the capacity does not have to be equal to the value given by <code>with_capacity</code>.</p>
<p>But, <em>in practice currently</em>, if you use <code>with_capacity</code> <a rel="external" href="https://doc.rust-lang.org/src/alloc/raw_vec.rs.html#414-428">it will ask the allocator</a> for that <em>exact</em> amount and won't reallocate until there are more entries than the initial capacity:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let mut</span><span> vec</span><span style="color: #F29E74;"> =</span><span style="color: #73D0FF;"> Vec</span><span style="color: #F29E74;">::</span><span style="color: #FFCD66;">with_capacity</span><span>(</span><span style="color: #DFBFFF;">10</span><span>);</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFCD66;">assert_eq!</span><span>(vec</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">len</span><span>(),</span><span style="color: #DFBFFF;"> 0</span><span>);</span></span>
<span class="giallo-l"><span style="color: #FFCD66;">assert_eq!</span><span>(vec</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">capacity</span><span>(),</span><span style="color: #DFBFFF;"> 10</span><span>);</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFA659;">for</span><span> i</span><span style="color: #FFA659;"> in</span><span style="color: #DFBFFF;"> 0</span><span style="color: #F29E74;">..</span><span style="color: #DFBFFF;">10</span><span> {</span></span>
<span class="giallo-l"><span>    vec</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">push</span><span>(i);</span></span>
<span class="giallo-l"><span>}</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFCD66;">assert_eq!</span><span>(vec</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">len</span><span>(),</span><span style="color: #DFBFFF;"> 10</span><span>);</span></span>
<span class="giallo-l"><span style="color: #FFCD66;">assert_eq!</span><span>(vec</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">capacity</span><span>(),</span><span style="color: #DFBFFF;"> 10</span><span>);</span></span></code></pre>
<p>This brings us back to our initial implementation:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let mut</span><span> buffer</span><span style="color: #F29E74;"> =</span><span style="color: #73D0FF;"> BytesMut</span><span style="color: #F29E74;">::</span><span style="color: #FFCD66;">with_capacity</span><span>(byte_len);</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFA659;">while let</span><span style="color: #73D0FF;"> Some</span><span>(bytes)</span><span style="color: #F29E74;"> =</span><span> req</span><span style="color: #F29E74;">.</span><span>stream</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">try_next</span><span>()</span><span style="color: #F29E74;">.</span><span style="color: #FFA659;">await</span><span style="color: #F29E74;">?</span><span> {</span></span>
<span class="giallo-l"><span>    buffer</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">extend_from_slice</span><span>(</span><span style="color: #F29E74;">&amp;</span><span>bytes);</span></span>
<span class="giallo-l"><span>}</span></span></code></pre>
<p>We should only be allocating once during the call to <code>with_capacity</code>.  Both <code>len()</code> and <code>capacity()</code> <em>should</em> be equal and equal to our given capacity <code>byte_len</code>.  <em>Why</em> are they not equal and why does it, looking at the heap profile, look like there is a reallocation happening?</p>
<h3 id="inclusive-and-exclusive-ranges">Inclusive and Exclusive Ranges</h3>
<p>We're using standard <a rel="external" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/Range_requests#single_part_ranges">HTTP Range requests</a> for requesting byte ranges.  In rust parlance, they are Inclusive Ranges.  I.e,</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span>start</span><span style="color: #F29E74;">..=</span><span>end</span></span></code></pre>
<p>Instead of <em>Exclusive</em> ranges.  I.e, the standard <a rel="external" href="https://doc.rust-lang.org/std/ops/struct.Range.html"><code>Range</code></a></p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span>start</span><span style="color: #F29E74;">..</span><span>end</span></span></code></pre>
<p>And essentially everything in rust is expecting a <code>Range</code> instead of <a rel="external" href="https://doc.rust-lang.org/std/ops/struct.RangeInclusive.html"><code>RangeInclusive</code></a>.  But when making http range requests we need to convert the other way.</p>
<p>And so to go from <em>exclusive</em> to <em>inclusive</em>:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let</span><span> start</span><span style="color: #F29E74;"> =</span><span> range</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">start</span><span>();</span></span>
<span class="giallo-l"><span style="color: #FFA659;">let</span><span> end</span><span style="color: #F29E74;"> =</span><span> range</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">end</span><span>()</span><span style="color: #F29E74;"> -</span><span style="color: #DFBFFF;"> 1</span><span>;</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFA659;">let</span><span> inclusive</span><span style="color: #F29E74;"> =</span><span> start</span><span style="color: #F29E74;">..=</span><span>end;</span></span></code></pre>
<p>And to go from <em>inclusive</em> to <em>exclusive</em>:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let</span><span> start</span><span style="color: #F29E74;"> =</span><span> range</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">start</span><span>();</span></span>
<span class="giallo-l"><span style="color: #FFA659;">let</span><span> end</span><span style="color: #F29E74;"> =</span><span> range</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">end</span><span>()</span><span style="color: #F29E74;"> +</span><span style="color: #DFBFFF;"> 1</span><span>;</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFA659;">let</span><span> exclusive</span><span style="color: #F29E74;"> =</span><span> start</span><span style="color: #F29E74;">..</span><span>end;</span></span></code></pre><h3 id="cache-keys-and-inclusive-ranges">Cache Keys and Inclusive Ranges</h3>
<p>Our <code>CacheKey</code> implementation, we store the start &amp; end as an exclusive range.</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">fn</span><span style="color: #FFCD66;"> to_cache_key</span><span>(path</span><span style="color: #F29E74;">: &amp;</span><span style="color: #73D0FF;">str</span><span>, range</span><span style="color: #F29E74;">:</span><span style="color: #73D0FF;"> RangeInclusive</span><span>&lt;</span><span style="color: #73D0FF;">usize</span><span>&gt;)</span><span style="color: #F29E74;"> -&gt;</span><span style="color: #73D0FF;"> CacheKey</span><span> {</span></span>
<span class="giallo-l"><span style="color: #73D0FF;">    CacheKey</span><span> {</span></span>
<span class="giallo-l"><span>        path</span><span style="color: #F29E74;">:</span><span> path</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">to_string</span><span>(),</span></span>
<span class="giallo-l"><span>        start</span><span style="color: #F29E74;">:</span><span> range</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">start</span><span>(),</span></span>
<span class="giallo-l"><span>        end</span><span style="color: #F29E74;">:</span><span> range</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">end</span><span>()</span><span style="color: #F29E74;"> -</span><span style="color: #DFBFFF;"> 1</span><span>,</span></span>
<span class="giallo-l"><span>    }</span></span>
<span class="giallo-l"><span>}</span></span></code></pre>
<p>Then we use this cache key to ask how much we should allocate:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let</span><span> byte_len</span><span style="color: #F29E74;"> =</span><span> cache_key</span><span style="color: #F29E74;">.</span><span>end </span><span style="color: #F29E74;">-</span><span> cache_key</span><span style="color: #F29E74;">.</span><span>start;</span></span></code></pre>
<p>Then in our backing request to our object storage, we were converting it <em>back</em> into an inclusive range by:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let</span><span> range</span><span style="color: #F29E74;"> =</span><span style="color: #73D0FF;"> RangeRequest</span><span> {</span></span>
<span class="giallo-l"><span>    start</span><span style="color: #F29E74;">:</span><span> cache_key</span><span style="color: #F29E74;">.</span><span>start,</span></span>
<span class="giallo-l"><span>    end</span><span style="color: #F29E74;">:</span><span> cache_key</span><span style="color: #F29E74;">.</span><span>end </span><span style="color: #F29E74;">+</span><span style="color: #DFBFFF;"> 1</span></span>
<span class="giallo-l"><span>};</span></span></code></pre>
<p>Can you spot the issue with the code above?</p>
<p>What is wrong with our implementation here?</p>
<p>If you go back and re-read how to convert from range to the other, you <em>might</em> catch it.</p>
<p>That's right: the conversion in the above code is <em>backwards</em>.  We were converting it the wrong way!  The <code>byte_len</code> was <em>always</em> two bytes short.  Meaning that the <code>BytesMut</code> would <em>always</em> reallocate.</p>
<p>To make matters worse: even though our <code>byte_len</code> was not the <em>right</em> length, <strong>the two errors cancelled eachother out</strong>.  We ended up inadvertently sending the correct request to the object store, our downstream services got the byte ranges they wanted, and the bug went undetected.  That is, until we reach our assigned memory limits...</p>
<p>Adding some debug assertions in the code it was easy to make our existing tests fail when they ran:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let mut</span><span> buffer</span><span style="color: #F29E74;"> =</span><span style="color: #73D0FF;"> BytesMut</span><span style="color: #F29E74;">::</span><span style="color: #FFCD66;">with_capacity</span><span>(byte_len);</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFA659;">while let</span><span style="color: #73D0FF;"> Some</span><span>(bytes)</span><span style="color: #F29E74;"> =</span><span> req</span><span style="color: #F29E74;">.</span><span>stream</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">try_next</span><span>()</span><span style="color: #F29E74;">.</span><span style="color: #FFA659;">await</span><span style="color: #F29E74;">?</span><span> {</span></span>
<span class="giallo-l"><span>    buffer</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">extend_from_slice</span><span>(</span><span style="color: #F29E74;">&amp;</span><span>bytes);</span></span>
<span class="giallo-l"><span>}</span></span>
<span class="giallo-l"></span>
<span class="giallo-l"><span style="color: #FFCD66;">debug_assert_eq!</span><span>(bytes</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">len</span><span>(), byte_len);</span></span>
<span class="giallo-l"><span style="color: #FFCD66;">debug_assert_eq!</span><span>(bytes</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">capacity</span><span>(), byte_len);</span></span></code></pre><h2 id="the-fix">The Fix</h2>
<p>So the fix in the end was simple: do a proper inclusive/exclusive conversion, which would mean that we only allocate as much as we need.</p>
<p>Converting to the exclusive range cache key:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">fn</span><span style="color: #FFCD66;"> to_cache_key</span><span>(path</span><span style="color: #F29E74;">: &amp;</span><span style="color: #73D0FF;">str</span><span>, range</span><span style="color: #F29E74;">:</span><span style="color: #73D0FF;"> RangeInclusive</span><span>&lt;</span><span style="color: #73D0FF;">usize</span><span>&gt;)</span><span style="color: #F29E74;"> -&gt;</span><span style="color: #73D0FF;"> CacheKey</span><span> {</span></span>
<span class="giallo-l"><span style="color: #73D0FF;">    CacheKey</span><span> {</span></span>
<span class="giallo-l"><span>        path</span><span style="color: #F29E74;">:</span><span> path</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">to_string</span><span>(),</span></span>
<span class="giallo-l"><span>        start</span><span style="color: #F29E74;">:</span><span> range</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">start</span><span>(),</span></span>
<span class="giallo-l"><span>        end</span><span style="color: #F29E74;">:</span><span> range</span><span style="color: #F29E74;">.</span><span style="color: #FFCD66;">end</span><span>()</span><span style="color: #F29E74;"> +</span><span style="color: #DFBFFF;"> 1</span><span>,</span></span>
<span class="giallo-l"><span>    }</span></span>
<span class="giallo-l"><span>}</span></span></code></pre>
<p>Converting back to the inclusive range request:</p>
<pre class="giallo" style="color: #CCCAC2; background-color: #1F2430;"><code data-lang="rust"><span class="giallo-l"><span style="color: #FFA659;">let</span><span> range</span><span style="color: #F29E74;"> =</span><span style="color: #73D0FF;"> RangeRequest</span><span> {</span></span>
<span class="giallo-l"><span>    start</span><span style="color: #F29E74;">:</span><span> cache_key</span><span style="color: #F29E74;">.</span><span>start,</span></span>
<span class="giallo-l"><span>    end</span><span style="color: #F29E74;">:</span><span> cache_key</span><span style="color: #F29E74;">.</span><span>end </span><span style="color: #F29E74;">-</span><span style="color: #DFBFFF;"> 1</span></span>
<span class="giallo-l"><span>};</span></span></code></pre>
<p>With this in place, everything worked without having to stop using <code>Bytes</code>, and preventing further deep changes.</p>
<h2 id="conclusions-thoughts">Conclusions &amp; Thoughts</h2>
<p>While rust is great at managing memory for you, there are situations where you need to keep a close eye on how much memory is being used. A cache service is a great example of that.</p>
<p>What <em>would</em> have been great from the start of the language, and definitely too late to change now, would be designing some of the standard library with fallible allocations from the get go.  If we had an API shaped for that, we would be able to catch errors like this much easier. Yes there are now methods like <code>try_reserve</code> on <code>Vec</code>, but downstream abstractions like <code>BytesMut</code> do not have the same methods.  Thinking this through: for a language that prides itself on explicit behaviour, this feels like one area where it could be less implicit.</p>
<p>In fairness, there could be more structure in place in the cache implementation to prevent this sort of bug from appearing, like using types more strongly to represent ranges etc.. If nothing else, it goes to show that sometimes bugs can be <em>deceptively</em> simple to fix, and having the tools to profile applications is vitally important.</p>

  </section>
</article>


        </div>
    </body>
</html>
